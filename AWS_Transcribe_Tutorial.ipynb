{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AWS Transcribe Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paras55/GPT2_text_generation/blob/master/AWS_Transcribe_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFjA_HIurMwL"
      },
      "source": [
        "### **Import packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToJdrttfq5AM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13abccb-4429-4f41-e6d4-559597e9db76"
      },
      "source": [
        "!pip install boto3\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import boto3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a5/892ed5d2959b1fdf4f8aaccf96b299e57dd7f06db7072592901fbaa36d79/boto3-1.17.54-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/50/ac379fa31377f5d316cad8967db9f73c50cd61b80153269bfd7d8b964fc8/s3transfer-0.4.0-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.9MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.54\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/e1/59cc39d22d44e64e96186db87d6e670e2119822d16299e18d0500198abb4/botocore-1.20.54-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.54->boto3) (2.8.1)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.54->boto3) (1.15.0)\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, urllib3, botocore, s3transfer, boto3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.17.54 botocore-1.20.54 jmespath-0.10.0 s3transfer-0.4.0 urllib3-1.26.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NllJa_Vauvpu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrP_t1j5rdix"
      },
      "source": [
        "### **Initialize the job**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdFwDLMeq51T"
      },
      "source": [
        "transcribe = boto3.client('transcribe',\n",
        "                          aws_access_key_id='AKIA5LIHLLFAQMQB6NZU', aws_secret_access_key='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',\n",
        "                          region_name = 'ap-south-1')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNfgzRWvrwBq"
      },
      "source": [
        "def check_job_name(job_name):\n",
        "  job_verification = True\n",
        "  \n",
        "  # all the transcriptions\n",
        "  existed_jobs = transcribe.list_transcription_jobs()\n",
        "  \n",
        "  for job in existed_jobs['TranscriptionJobSummaries']:\n",
        "    if job_name == job['TranscriptionJobName']:\n",
        "      job_verification = False\n",
        "      break\n",
        "\n",
        "  if job_verification == False:\n",
        "    command = input(job_name + \" has existed. \\nDo you want to override the existed job (Y/N): \")\n",
        "    if command.lower() == \"y\" or command.lower() == \"yes\":\n",
        "      transcribe.delete_transcription_job(TranscriptionJobName=job_name)\n",
        "    elif command.lower() == \"n\" or command.lower() == \"no\":\n",
        "      job_name = input(\"Insert new job name? \")\n",
        "      check_job_name(job_name)\n",
        "    else: \n",
        "      print(\"Input can only be (Y/N)\")\n",
        "      command = input(job_name + \" has existed. \\nDo you want to override the existed job (Y/N): \")\n",
        "  return job_name"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BerOkh70uwLz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76bmU9eSr0WH"
      },
      "source": [
        "#### **For Single Speaker files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEtocAOJrv-u"
      },
      "source": [
        "def amazon_transcribe(audio_file_name):\n",
        "  job_uri = # your S3 access link\n",
        "  # Usually, I put like this to automate the process with the file name\n",
        "  # \"s3://bucket_name\" + audio_file_name \n",
        "\n",
        "  # Usually, file names have spaces and have the file extension like .mp3\n",
        "  # we take only a file name and delete all the space to name the job\n",
        "  job_name = (audio_file_name.split('.')[0]).replace(\" \", \"\")\n",
        "  \n",
        "  # file format\n",
        "  file_format = audio_file_name.split('.')[1]\n",
        "\n",
        "  # check if name is taken or not\n",
        "  job_name = check_job_name(job_name)\n",
        "  transcribe.start_transcription_job(\n",
        "      TranscriptionJobName=job_name,\n",
        "      Media={'MediaFileUri': job_uri},\n",
        "      MediaFormat = file_format,\n",
        "      LanguageCode='en-US')\n",
        "  \n",
        "  while True:\n",
        "    result = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
        "    if result['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
        "      print(\"FAILED\")\n",
        "      break\n",
        "    time.sleep(15)\n",
        "\n",
        "  if result['TranscriptionJob']['TranscriptionJobStatus'] == \"COMPLETED\":\n",
        "    data = pd.read_json(result['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
        "  \n",
        "  return data['results'][1][0]['transcript']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDmtNbJuw5C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEirfSA1thNl"
      },
      "source": [
        "#### **For Multiple Speakers files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD-kjcNorwHK"
      },
      "source": [
        "def amazon_transcribe(audio_file_name, max_speakers = -1):\n",
        "\n",
        "  if max_speakers > 10:\n",
        "    raise ValueError(\"Maximum detected speakers is 10.\")\n",
        "\n",
        "  job_uri = 's3://transcriber-test12/yash.wav'\n",
        "  job_name = (audio_file_name.split('.')[0]).replace(\" \", \"\")\n",
        "  \n",
        "  # check if name is taken or not\n",
        "  job_name = check_job_name(job_name)\n",
        "  \n",
        "  if max_speakers != -1:\n",
        "    transcribe.start_transcription_job(\n",
        "        TranscriptionJobName=job_name,\n",
        "        Media={'MediaFileUri': job_uri},\n",
        "        MediaFormat=audio_file_name.split('.')[1],\n",
        "        LanguageCode='hi-IN',\n",
        "        Settings = {'ShowSpeakerLabels': True,\n",
        "                  'MaxSpeakerLabels': max_speakers\n",
        "                  }\n",
        "    )\n",
        "  else: \n",
        "    transcribe.start_transcription_job(\n",
        "        TranscriptionJobName=job_name,\n",
        "        Media={'MediaFileUri': job_uri},\n",
        "        MediaFormat=audio_file_name.split('.')[1],\n",
        "        LanguageCode='hi-IN',\n",
        "        Settings = {'ShowSpeakerLabels': True\n",
        "                  }\n",
        "    )    \n",
        "  \n",
        "  while True:\n",
        "    result = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
        "    if result['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
        "        break\n",
        "    time.sleep(15)\n",
        "  if result['TranscriptionJob']['TranscriptionJobStatus'] == 'COMPLETED':\n",
        "    data = pd.read_json(result['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
        "  return result"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voHWdjWdZMFL",
        "outputId": "fb11e5d2-b521-4019-f251-e12c029f2a0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "p=amazon_transcribe('yash.wav',2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yash has existed. \n",
            "Do you want to override the existed job (Y/N): y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjG_nIOBrwFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077ff8c8-356d-4745-880c-7cd3c6c5a04c"
      },
      "source": [
        "print(p)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'TranscriptionJob': {'TranscriptionJobName': 'yash', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'wav', 'Media': {'MediaFileUri': 's3://transcriber-test12/new.wav'}, 'Transcript': {'TranscriptFileUri': 'https://s3.ap-south-1.amazonaws.com/aws-transcribe-ap-south-1-prod/917527812417/yash/55096c72-7dac-4733-b10d-7830acb37bf8/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjECkaCmFwLXNvdXRoLTEiRzBFAiATgujUos84D%2F4mga0Cu0%2BRFRSfIIVtIpROh7kwHzgoUwIhAKqfZydz0kAMDIytELsI8jY9p%2F7gXcUsaGupNCdolNVFKr8DCJL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQAhoMNjYzMDE5MTE5ODM2IgyC3KbGjXwPVgv0xvUqkwNB6JQk5aVT0Vsq9g2xnTK0UOxEr9G2ZHh%2F8KJLU4lYoRAFaKgf9bZeDfTTrulhx6twlMybxJ%2B39l9ELzX7w35MZyU%2Bx6sLY06Cl%2BUnkPwGLXx2Uijy8E34XvxR97gruGpjzZOn25tX2kDSvRfAwV2jeHIwbrG3Oe8sUd4Cq6cTrdbzqCMBeM2zcC2GaNzPhWnsbK%2Beuolt%2B%2BmWfKJqpfb6EQiXUc34Ya1ZaRRjHhMxBB9lCko8QlPXanoO5czVBzXHto0fs9Oh66Z2jPTv4%2BeCtfrbBm2nnkKuNCkNcqRIt7pEC9QgkoZdrppHLbPa8JBTl6x5LRYsEqjGJstlr81hIOL7SyPwvtfhcSukNdFUqY1E0WoibRHZwvsoucqE%2BoXplNQw40iu3cn0xGsPLNILqlL6XSGrOZrcI%2FSiAguaVD7yBC5vDOIZFGb868Qs5rs7CE9ZrTrUqISg5HEE%2BQBjrlR2Xf4RSzx4O1LrddrqhOtUHvitvHIrCmXtEqVl777nAokR8sVohhZunvfxMRKKDACWMPmY%2FIMGOusBsO%2BQiouvghI6EKpyjZgHyl%2FfVXvw%2FZF0sAuQUSjjWFdYWj5WeRKBZINu7j3LK%2BnAVAKu3ueb%2B5YTmK8Phugf7GJDbAGpcA0NXfkiyAPsORn%2Bxxktz%2FP%2F6xRqvgPsOgTlMYjhW89FP5GqwOH9vV9Y8fP1NeGIrUQkW8mfhP5atD56Hvufw2nVnGyVCb91p6FHljhKa08YPdaNUPpa8O%2Fe7yuLHi781BxgfANcDq5pqrcnstSJDYIi2dtcqINB4x%2FvsOKC%2BBBjgnYzjMGxNFw4rtfN7ZP8UxFdLzeaH1GGsPHThY35KzV3UTMH1Q%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210420T184515Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIAZUXYE4TOOWBSDX5C%2F20210420%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Signature=cdac310cb317a4296e7e0b6ec58b7c391b119e0b6d1b304a5157ff6cbd45d0a0'}, 'StartTime': datetime.datetime(2021, 4, 20, 18, 43, 59, 490000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2021, 4, 20, 18, 43, 59, 472000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2021, 4, 20, 18, 45, 10, 300000, tzinfo=tzlocal()), 'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 2, 'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '85b1f922-e751-41e2-8368-6113f221dde3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Tue, 20 Apr 2021 18:45:15 GMT', 'x-amzn-requestid': '85b1f922-e751-41e2-8368-6113f221dde3', 'content-length': '2025', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO5NWgG-t1zc"
      },
      "source": [
        "#### **Read the json files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9erCddjnY79J"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/AWS Transcribe reader\")\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/AWS Transcribe reader\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YJDKplhaa4b"
      },
      "source": [
        "import json\n",
        "import datetime\n",
        "import time as ptime\n",
        "\n",
        "def read_output(filename):\n",
        "  # example filename: audio.json\n",
        "  \n",
        "  # take the input as the filename\n",
        "  \n",
        "  filename = (filename).split('.')[0]\n",
        "\n",
        "  # Create an output txt file\n",
        "  print(filename+'.txt')\n",
        "  with open(filename+'.txt','w') as w:\n",
        "    with open(filename+'.json') as f:\n",
        "\n",
        "      data=json.loads(f.read())\n",
        "      labels = data['results']['speaker_labels']['segments']\n",
        "      speaker_start_times={}\n",
        "      \n",
        "      for label in labels:\n",
        "        for item in label['items']:\n",
        "          speaker_start_times[item['start_time']] = item['speaker_label']\n",
        "\n",
        "      items = data['results']['items']\n",
        "      lines = []\n",
        "      line = ''\n",
        "      time = 0\n",
        "      speaker = 'null'\n",
        "      i = 0\n",
        "\n",
        "      # loop through all elements\n",
        "      for item in items:\n",
        "        i = i+1\n",
        "        content = item['alternatives'][0]['content']\n",
        "\n",
        "        # if it's starting time\n",
        "        if item.get('start_time'):\n",
        "          current_speaker = speaker_start_times[item['start_time']]\n",
        "        \n",
        "        # in AWS output, there are types as punctuation\n",
        "        elif item['type'] == 'punctuation':\n",
        "          line = line + content\n",
        "\n",
        "        # handle different speaker\n",
        "        if current_speaker != speaker:\n",
        "          if speaker:\n",
        "            lines.append({'speaker':speaker, 'line':line, 'time':time})\n",
        "          line = content\n",
        "          speaker = current_speaker\n",
        "          time = item['start_time']\n",
        "          \n",
        "        elif item['type'] != 'punctuation':\n",
        "          line = line + ' ' + content\n",
        "      lines.append({'speaker': speaker, 'line': line,'time': time})\n",
        "\n",
        "      # sort the results by the time\n",
        "      sorted_lines = sorted(lines,key=lambda k: float(k['time']))\n",
        "\n",
        "      # write into the .txt file\n",
        "      for line_data in sorted_lines:\n",
        "        line = '[' + str(datetime.timedelta(seconds=int(round(float(line_data['time']))))) + '] ' + line_data.get('speaker') + ': ' + line_data.get('line')\n",
        "        w.write(line + '\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn74j9QoabGa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oXM0ZKVka1S"
      },
      "source": [
        "#### **Upload files to S3 storage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ndhroaska7f"
      },
      "source": [
        "# define AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and bucket_name\n",
        "# bucket_name: name of s3 storage folder\n",
        "s3 = boto3.client('s3', \n",
        "  aws_access_key_id = AWS_ACCESS_KEY_ID,\n",
        "  aws_secret_access_key = AWS_SECRET_ACCESS_KEY,\n",
        "  region_name = \"us-east-2\")\n",
        "s3.upload_file(file_name, bucket_name, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U06rTyGNl6Ij"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHdwmM29kQte"
      },
      "source": [
        "#### **Add custom vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyO3djThu-h8"
      },
      "source": [
        "def vocab_name(custom_name):\n",
        "  vocab = pd.DataFrame([['Los-Angeles', np.nan, np.nan, \"Los Angeles\"], [\"F.B.I.\", \"ɛ f b i aɪ\", np.nan, \"FBI\"], [\"Etienne\", np.nan, \"eh-tee-en\", np.nan]], columns=['Phrase', 'IPA', 'SoundsLike', 'DisplayAs'])\n",
        "  vocab.to_csv(custom_name+'.csv', header=True, index=None, sep='\\t')\n",
        "  import csv\n",
        "  import time\n",
        "  csv_file = 'custom_name+'.csv\n",
        "  txt_file = 'custom_name+'.txt\n",
        "  with open(txt_file, \"w\") as my_output_file:\n",
        "    with open(csv_file, \"r\") as my_input_file:\n",
        "      my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
        "    my_output_file.close()\n",
        "  ptime.sleep(30) # wait for the file to finish\n",
        "  bucket_name = #name of the S3 bucket\n",
        "  s3.upload_file(txt_file, bucket_name, txt_file)\n",
        "  ptime.sleep(60)\n",
        "  response = transcribe.create_vocabulary(\n",
        "    VocabularyName = custom_name,\n",
        "    LanguageCode='en-US',\n",
        "    VocabularyFileUri = \"your s3 link\" + txt_file)\n",
        "    # the link usually is bucketname.region.amazonaws.com\n",
        "# after running vocab_name, we can check the status through this line\n",
        "# if it's ready, the VocabularyState will be 'READY'\n",
        "transcribe.list_vocabularies()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}